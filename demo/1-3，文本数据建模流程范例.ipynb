{"cells":[{"metadata":{"cell_type":"code","id":"D9CE765FFC1B404E814506366BCA7372","jupyter":{},"tags":[],"mdEditEnable":false},"cell_type":"markdown","source":["## 1-3,文本数据建模流程范例\n","### 一，准备数据\n","imdb数据集的目标是根据电影评论的文本内容预测评论的情感标签。\n","\n","训练集有20000条电影评论文本，测试集有5000条电影评论文本，其中正面评论和负面评论都各占一半。\n","\n","文本数据预处理较为繁琐，包括中文切词（本示例不涉及），构建词典，编码转换，序列填充，构建数据管道等等。\n","\n","在tensorflow中完成文本数据预处理的常用方案有两种，第一种是利用tf.keras.preprocessing中的Tokenizer词典构建工具和tf.keras.utils.Sequence构建文本数据生成器管道。\n","\n","第二种是使用tf.data.Dataset搭配.keras.layers.experimental.preprocessing.TextVectorization预处理层。\n","\n","\n","第二种方法为TensorFlow原生方式，相对也更加简单一些。\n","\n","我们此处介绍第二种方法。\n","\n","![Image Name](https://cdn.kesci.com/upload/image/q9e0hrqoze.jpg)\n"]},{"cell_type":"code","source":["!git clone https://github.com/Dreaming-future/eat_tensorflow2_in_30_days.git\n","%cd eat_tensorflow2_in_30_days"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rns9GIrhnx8H","executionInfo":{"status":"ok","timestamp":1660736925352,"user_tz":-480,"elapsed":8199,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}},"outputId":"8a8d168d-34df-41c4-cbb4-4fab2309ebc8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'eat_tensorflow2_in_30_days'...\n","remote: Enumerating objects: 12967, done.\u001b[K\n","remote: Counting objects: 100% (4/4), done.\u001b[K\n","remote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 12967 (delta 0), reused 4 (delta 0), pack-reused 12963\u001b[K\n","Receiving objects: 100% (12967/12967), 52.33 MiB | 25.00 MiB/s, done.\n","Resolving deltas: 100% (12157/12157), done.\n","Checking out files: 100% (12460/12460), done.\n","/content/eat_tensorflow2_in_30_days\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","#注：全部代码在tensorflow 2.1版本测试通过\n","tf.print(\"tensorflow version:\",tf.__version__)\n","\n","a = tf.constant(\"hello\")\n","b = tf.constant(\"tensorflow2\")\n","c = tf.strings.join([a,b],\" \")\n","tf.print(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ChDMW53XoZ4h","executionInfo":{"status":"ok","timestamp":1660736938853,"user_tz":-480,"elapsed":9286,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}},"outputId":"7b15af9f-ae9d-407f-aadf-8c7c423a5772"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow version: 2.8.2\n","hello tensorflow2\n"]}]},{"metadata":{"id":"BECB92A34B2042C2BD4BE9AAB81BA16B","jupyter":{},"tags":[],"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660736951044,"user_tz":-480,"elapsed":9786,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}},"outputId":"f385f2cd-3ae6-449e-a3bb-80ff290136f0"},"cell_type":"code","outputs":[{"output_type":"stream","name":"stdout","text":["['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i', 'this', 'that', 'was', 'as', 'for', 'with', 'movie', 'but', 'film', 'on', 'not', 'you', 'his', 'are', 'have', 'be', 'he', 'one', 'its', 'at', 'all', 'by', 'an', 'they', 'from', 'who', 'so', 'like', 'her', 'just', 'or', 'about', 'has', 'if', 'out', 'some', 'there', 'what', 'good', 'more', 'when', 'very', 'she', 'even', 'my', 'no', 'would', 'up', 'time', 'only', 'which', 'story', 'really', 'their', 'were', 'had', 'see', 'can', 'me', 'than', 'we', 'much', 'well', 'get', 'been', 'will', 'into', 'people', 'also', 'other', 'do', 'bad', 'because', 'great', 'first', 'how', 'him', 'most', 'dont', 'made', 'then', 'them', 'films', 'movies', 'way', 'make', 'could', 'too', 'any']\n"]}],"source":["import numpy as np \n","import pandas as pd \n","from matplotlib import pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras import models,layers,preprocessing,optimizers,losses,metrics\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","import re,string\n","\n","train_data_path = \"./data/imdb/train.csv\"\n","test_data_path =  \"./data/imdb/test.csv\"\n","\n","MAX_WORDS = 10000  # 仅考虑最高频的10000个词\n","MAX_LEN = 200  # 每个样本保留200个词的长度\n","BATCH_SIZE = 20 \n","\n","\n","#构建管道\n","def split_line(line):\n","    arr = tf.strings.split(line,\"\\t\")\n","    label = tf.expand_dims(tf.cast(tf.strings.to_number(arr[0]),tf.int32),axis = 0)\n","    text = tf.expand_dims(arr[1],axis = 0)\n","    return (text,label)\n","\n","ds_train_raw =  tf.data.TextLineDataset(filenames = [train_data_path]) \\\n","   .map(split_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n","   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n","   .prefetch(tf.data.experimental.AUTOTUNE)\n","\n","ds_test_raw = tf.data.TextLineDataset(filenames = [test_data_path]) \\\n","   .map(split_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n","   .batch(BATCH_SIZE) \\\n","   .prefetch(tf.data.experimental.AUTOTUNE)\n","\n","\n","#构建词典\n","def clean_text(text):\n","    lowercase = tf.strings.lower(text)\n","    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n","    cleaned_punctuation = tf.strings.regex_replace(stripped_html,\n","         '[%s]' % re.escape(string.punctuation),'')\n","    return cleaned_punctuation\n","\n","vectorize_layer = TextVectorization(\n","    standardize=clean_text,\n","    split = 'whitespace',\n","    max_tokens=MAX_WORDS-1, #有一个留给占位符\n","    output_mode='int',\n","    output_sequence_length=MAX_LEN)\n","\n","ds_text = ds_train_raw.map(lambda text,label: text)\n","vectorize_layer.adapt(ds_text)\n","print(vectorize_layer.get_vocabulary()[0:100])\n","\n","\n","#单词编码\n","ds_train = ds_train_raw.map(lambda text,label:(vectorize_layer(text),label)) \\\n","    .prefetch(tf.data.experimental.AUTOTUNE)\n","ds_test = ds_test_raw.map(lambda text,label:(vectorize_layer(text),label)) \\\n","    .prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":3},{"metadata":{"id":"DC625B979DD94E5A8CDF2B521AC0B953","jupyter":{},"tags":[],"mdEditEnable":false},"cell_type":"markdown","source":["## 二，定义模型\n","使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n","\n","此处选择使用继承Model基类构建自定义模型。"]},{"metadata":{"id":"E7ED911D052A459D84B23FCC682368C0","jupyter":{},"tags":[],"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660736951046,"user_tz":-480,"elapsed":85,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}},"outputId":"37e3b7e9-d008-4045-beec-ff4e21da37b0"},"cell_type":"code","outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"cnn_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  70000     \n","                                                                 \n"," conv_1 (Conv1D)             multiple                  576       \n","                                                                 \n"," max_pooling1d (MaxPooling1D  multiple                 0         \n"," )                                                               \n","                                                                 \n"," conv_2 (Conv1D)             multiple                  4224      \n","                                                                 \n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  6145      \n","                                                                 \n","=================================================================\n","Total params: 80,945\n","Trainable params: 80,945\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["tf.keras.backend.clear_session()\n","\n","class CnnModel(models.Model):\n","    def __init__(self):\n","        super(CnnModel, self).__init__()\n","        \n","    def build(self,input_shape):\n","        self.embedding = layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN)\n","        self.conv_1 = layers.Conv1D(16, kernel_size= 5,name = \"conv_1\",activation = \"relu\")\n","        self.pool = layers.MaxPool1D()\n","        self.conv_2 = layers.Conv1D(128, kernel_size=2,name = \"conv_2\",activation = \"relu\")\n","        self.flatten = layers.Flatten()\n","        self.dense = layers.Dense(1,activation = \"sigmoid\")\n","        super(CnnModel,self).build(input_shape)\n","    \n","    def call(self, x):\n","        x = self.embedding(x)\n","        x = self.conv_1(x)\n","        x = self.pool(x)\n","        x = self.conv_2(x)\n","        x = self.pool(x)\n","        x = self.flatten(x)\n","        x = self.dense(x)\n","        return(x)\n","    \n","model = CnnModel()\n","model.build(input_shape =(None,MAX_LEN))\n","model.summary()"],"execution_count":4},{"metadata":{"id":"60D96F8A5550491B9BEC65963031A2BB","jupyter":{},"tags":[],"mdEditEnable":false},"cell_type":"markdown","source":["## 三，训练模型\n","训练模型通常有3种方法，内置fit方法，内置train_on_batch方法，以及自定义训练循环。此处我们通过自定义训练循环训练模型"]},{"metadata":{"id":"765A7F0E93D64ED79C275AA1C177B170","jupyter":{},"tags":[],"scrolled":false,"executionInfo":{"status":"ok","timestamp":1660736951049,"user_tz":-480,"elapsed":47,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}}},"cell_type":"code","outputs":[],"source":["#打印时间分割线\n","@tf.function\n","def printbar():\n","    today_ts = tf.timestamp()%(24*60*60)\n","\n","    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n","    minite = tf.cast((today_ts%3600)//60,tf.int32)\n","    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n","    \n","    def timeformat(m):\n","        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n","            return(tf.strings.format(\"0{}\",m))\n","        else:\n","            return(tf.strings.format(\"{}\",m))\n","    \n","    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n","                timeformat(second)],separator = \":\")\n","    tf.print(\"==========\"*8+timestring)\n"],"execution_count":5},{"metadata":{"id":"96E54F5013064242867C7A7821052B8D","jupyter":{},"tags":[],"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660737049244,"user_tz":-480,"elapsed":98238,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}},"outputId":"33bbe78d-544c-4501-aea9-7bf66cb7e2f8"},"cell_type":"code","outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================19:49:35\n","Epoch=1,Loss:0.427575409,Accuracy:0.7842,Valid Loss:0.322231948,Valid Accuracy:0.8616\n","\n","================================================================================19:49:49\n","Epoch=2,Loss:0.248446912,Accuracy:0.9015,Valid Loss:0.334875435,Valid Accuracy:0.863\n","\n","================================================================================19:50:05\n","Epoch=3,Loss:0.183869034,Accuracy:0.9305,Valid Loss:0.35353741,Valid Accuracy:0.869\n","\n","================================================================================19:50:21\n","Epoch=4,Loss:0.131010264,Accuracy:0.9538,Valid Loss:0.42781049,Valid Accuracy:0.8648\n","\n","================================================================================19:50:35\n","Epoch=5,Loss:0.0903860778,Accuracy:0.9687,Valid Loss:0.540265203,Valid Accuracy:0.8576\n","\n","================================================================================19:50:49\n","Epoch=6,Loss:0.0561889075,Accuracy:0.98155,Valid Loss:0.684412837,Valid Accuracy:0.852\n","\n"]}],"source":["optimizer = optimizers.Nadam()\n","loss_func = losses.BinaryCrossentropy()\n","\n","train_loss = metrics.Mean(name='train_loss')\n","train_metric = metrics.BinaryAccuracy(name='train_accuracy')\n","\n","valid_loss = metrics.Mean(name='valid_loss')\n","valid_metric = metrics.BinaryAccuracy(name='valid_accuracy')\n","\n","\n","@tf.function\n","def train_step(model, features, labels):\n","    with tf.GradientTape() as tape:\n","        predictions = model(features,training = True)\n","        loss = loss_func(labels, predictions)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","    train_loss.update_state(loss)\n","    train_metric.update_state(labels, predictions)\n","    \n","\n","@tf.function\n","def valid_step(model, features, labels):\n","    predictions = model(features,training = False)\n","    batch_loss = loss_func(labels, predictions)\n","    valid_loss.update_state(batch_loss)\n","    valid_metric.update_state(labels, predictions)\n","\n","\n","def train_model(model,ds_train,ds_valid,epochs):\n","    for epoch in tf.range(1,epochs+1):\n","        \n","        for features, labels in ds_train:\n","            train_step(model,features,labels)\n","\n","        for features, labels in ds_valid:\n","            valid_step(model,features,labels)\n","        \n","        #此处logs模板需要根据metric具体情况修改\n","        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}' \n","        \n","        if epoch%1==0:\n","            printbar()\n","            tf.print(tf.strings.format(logs,\n","            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n","            tf.print(\"\")\n","        \n","        train_loss.reset_states()\n","        valid_loss.reset_states()\n","        train_metric.reset_states()\n","        valid_metric.reset_states()\n","        \n","train_model(model,ds_train,ds_test,epochs = 6)"],"execution_count":6},{"metadata":{"id":"D1613A4B9A124DC889CA24D7198D1F2A","jupyter":{},"tags":[],"collapsed":false,"scrolled":false,"mdEditEnable":false},"cell_type":"markdown","source":["## 四，评估模型\n","通过自定义训练循环训练的模型没有经过编译，无法直接使用model.evaluate(ds_valid)方法"]},{"metadata":{"id":"2D258BEC889C4CE19A7FD914FC024120","jupyter":{},"tags":[],"scrolled":false,"executionInfo":{"status":"ok","timestamp":1660737049246,"user_tz":-480,"elapsed":15,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}}},"cell_type":"code","outputs":[],"source":["def evaluate_model(model,ds_valid):\n","    for features, labels in ds_valid:\n","         valid_step(model,features,labels)\n","    logs = 'Valid Loss:{},Valid Accuracy:{}' \n","    tf.print(tf.strings.format(logs,(valid_loss.result(),valid_metric.result())))\n","    \n","    valid_loss.reset_states()\n","    train_metric.reset_states()\n","    valid_metric.reset_states()\n","\n"],"execution_count":7},{"metadata":{"id":"51DCE41F3D934162B016A6DEAD21FD63","jupyter":{},"tags":[],"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660737051074,"user_tz":-480,"elapsed":1839,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}},"outputId":"d4b63d97-63be-46ae-eb4d-0393df467013"},"cell_type":"code","outputs":[{"output_type":"stream","name":"stdout","text":["Valid Loss:0.684412837,Valid Accuracy:0.852\n"]}],"source":["evaluate_model(model,ds_test)"],"execution_count":8},{"metadata":{"id":"3ECE7551057F424C95449240D1F38F7F","jupyter":{},"tags":[],"mdEditEnable":false},"cell_type":"markdown","source":["## 五，使用模型\n","可以使用以下方法:\n","\n","model.predict(ds_test)\n","model(x_test)\n","model.call(x_test)\n","model.predict_on_batch(x_test)\n","推荐优先使用model.predict(ds_test)方法，既可以对Dataset，也可以对Tensor使用。"]},{"metadata":{"id":"D710B731513341A0AF275B5A5DB68513","jupyter":{},"tags":[],"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660737053980,"user_tz":-480,"elapsed":2919,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}},"outputId":"39d65b22-0465-4f6f-f79a-1956c8c45482"},"cell_type":"code","outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.03495839],\n","       [0.9994997 ],\n","       [0.9752555 ],\n","       ...,\n","       [0.9874332 ],\n","       [0.8025999 ],\n","       [1.        ]], dtype=float32)"]},"metadata":{},"execution_count":9}],"source":["model.predict(ds_test)"],"execution_count":9},{"metadata":{"id":"4F639B29A3A24ACAB2F39CDF766053F7","jupyter":{},"tags":[],"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660737053981,"user_tz":-480,"elapsed":16,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}},"outputId":"ef8ecf8b-6740-4f1d-b42e-099de2bfad77"},"cell_type":"code","outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[3.4958452e-02]\n"," [9.9949968e-01]\n"," [9.7525543e-01]\n"," [4.4705102e-09]\n"," [5.9378880e-01]\n"," [2.1900669e-05]\n"," [1.8581892e-07]\n"," [2.1438003e-03]\n"," [9.9972892e-01]\n"," [6.1539620e-01]\n"," [9.9998987e-01]\n"," [4.9500042e-01]\n"," [3.2090745e-07]\n"," [7.6256222e-01]\n"," [1.4764698e-06]\n"," [2.2403523e-01]\n"," [3.1194091e-04]\n"," [1.6794378e-01]\n"," [1.9782858e-06]\n"," [6.2702715e-01]], shape=(20, 1), dtype=float32)\n"]}],"source":["for x_test,_ in ds_test.take(1):\n","    print(model(x_test))\n","    #以下方法等价：\n","    #print(model.call(x_test))\n","    #print(model.predict_on_batch(x_test))"],"execution_count":10},{"metadata":{"id":"FDAF8663663D4B588B86DD13F118CB90","jupyter":{},"tags":[],"mdEditEnable":false},"cell_type":"markdown","source":["## 六，保存模型\n","推荐使用TensorFlow原生方式保存模型。"]},{"metadata":{"id":"5533A2B3DE614F3C9E22D82E5946FA8C","jupyter":{},"tags":[],"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660737057649,"user_tz":-480,"elapsed":3681,"user":{"displayName":"pikachu dkj","userId":"00676631053999804932"}},"outputId":"d3eeae6e-55d5-4c05-f22f-4b8fe73dd861"},"cell_type":"code","outputs":[{"output_type":"stream","name":"stdout","text":["export saved model.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.03495839],\n","       [0.9994997 ],\n","       [0.9752555 ],\n","       ...,\n","       [0.9874332 ],\n","       [0.8025999 ],\n","       [1.        ]], dtype=float32)"]},"metadata":{},"execution_count":11}],"source":["model.save('./data/tf_model_savedmodel', save_format=\"tf\")\n","print('export saved model.')\n","\n","model_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel')\n","model_loaded.predict(ds_test)"],"execution_count":11}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"1-3，文本数据建模流程范例.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}